{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    # Reads an image from the determined path\n",
    "    # The image has to have a bit-depth of 8 (each pixel's value is in the 0-255 range)\n",
    "    img_to_recognize = img.imread(path)\n",
    "    img_to_recognize = Image.fromarray(np.uint8(img_to_recognize))\n",
    "    img_to_recognize = img_to_recognize.resize((150, 150)) # Resizes the image to the appropriate size\n",
    "    img_to_recognize = img_to_recognize.convert('L') # Converts it to grayscale\n",
    "    img_to_recognize = np.array(img_to_recognize) # Converts it into an array\n",
    "    return img_to_recognize.flatten()/255 # Flattens and normalizes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(array):\n",
    "    # Displays the image represented by a flattened array\n",
    "    resized = np.resize(array, (150, 150))\n",
    "    fig = plt.imshow(resized, cmap=\"gray\")\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    fig\n",
    "\n",
    "\n",
    "def display_image_ind(matrix, index):\n",
    "    # Displays the image present in the row_{index} of the specified matrix\n",
    "    resized = np.resize(matrix[index], (150, 150))\n",
    "    fig = plt.imshow(resized, cmap=\"gray\")\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    fig\n",
    "\n",
    "\n",
    "def plot_portraits(images, titles, h, w, n_row, n_col):\n",
    "    plt.figure(figsize=(2.2 * n_col, 2.2 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.20)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [] # List that will house all individual arrays of images, it will become a 2D array later\n",
    "\n",
    "for file in os.listdir('data'):\n",
    "    images.append(read_image(os.path.join('data', file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matrix = np.row_stack(tuple(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    # X is the data matrix\n",
    "    mean = np.mean(X, axis=0)\n",
    "    centered_data = X-mean\n",
    "    U, S, Vh = np.linalg.svd(centered_data, full_matrices=False)\n",
    "    \n",
    "    return Vh, mean, centered_data, S**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh, average_matrix, subtracted, eigenvalues = pca(image_matrix)\n",
    "eigenfaces = Vh.reshape((434, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_eigenvalues = [eigenvalue/np.sum(eigenvalues) for eigenvalue in eigenvalues]\n",
    "count = 0\n",
    "total_var = 0\n",
    "var_values = []\n",
    "for eigenvalue in percent_eigenvalues:\n",
    "    total_var += eigenvalue\n",
    "    count += 1\n",
    "    var_values.append(total_var)\n",
    "    # if total_var > 0.95:\n",
    "    #     break\n",
    "\n",
    "print(\"Count:\", count, \"\\nTotal Variance:\", total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_values)\n",
    "plt.xticks(range(0,400,30))\n",
    "plt.xlim(-1, 400)\n",
    "# plt.savefig(os.path.join('images', 'accumulated variance.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(average_matrix)\n",
    "\n",
    "# plt.savefig(os.path.join('images', 'average face.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenface_titles = [f\"eigenface {434-i}\" for i in range(eigenfaces.shape[0])]\n",
    "# plot_portraits(eigenfaces[::-1], eigenface_titles, 150, 150, 2, 5) \n",
    "# plt.savefig(os.path.join('images', 'lowest eigenfaces.png'), bbox_inches='tight')\n",
    "\n",
    "eigenface_titles = [f\"eigenface {i+91}\" for i in range(eigenfaces.shape[0])]\n",
    "plot_portraits(eigenfaces[90:105,:], eigenface_titles, 150, 150, 2, 5) \n",
    "# plt.savefig(os.path.join('images', 'medium eigenfaces.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_ind(image_matrix, 142)\n",
    "# plt.savefig(os.path.join('images', 'original face.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(centered_data, eigenfaces, average, h, w, image_index):\n",
    "    weights = np.dot(centered_data, eigenfaces.T) # Gets the weight significance of each eigenface\n",
    "    weighted_vectors = np.dot(weights[image_index, :], eigenfaces) # Multiplies each eigenface by its weight\n",
    "    recovered_image = (average + weighted_vectors).reshape(h, w) # Adds each weighted eigenface to the average face\n",
    "    return recovered_image\n",
    "\n",
    "display_image(reconstruction(subtracted, Vh[:300,:], average_matrix, 150, 150, 142))\n",
    "# plt.savefig(os.path.join('images', 'reconstructed full face.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_outsider(eigenfaces, average, h, w, path):\n",
    "    outsider = read_image(path) # Reads the image\n",
    "    outsider = outsider - average # Centralizes the data\n",
    "    weights = np.dot(outsider, eigenfaces.T) # Gets the weight significance of each eigenface\n",
    "    weighted_vectors = np.dot(weights, eigenfaces) # Multiplies each eigenface by its weight\n",
    "    recovered_image = (average + weighted_vectors).reshape(h, w) # Adds each weighted eigenface to the average face\n",
    "    return recovered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(path, eig_num, face_limit, person_limit):\n",
    "    # Path is the file path, eig_num is the amount of wanted eigenfaces on the facespace\n",
    "    img_to_recognize = read_image(path)\n",
    "    subtracted_matrix_rec = img_to_recognize - average_matrix # Centralizes the inputted image\n",
    "    subtracted_matrix_rec = subtracted_matrix_rec.flatten()\n",
    "\n",
    "    eigenfaces_matrix = Vh[:eig_num,:] # Gets the requested amount of eigenfaces\n",
    "\n",
    "    weight = subtracted_matrix_rec @ eigenfaces_matrix.T # Gets the eigenface weights\n",
    "\n",
    "    projection = eigenfaces_matrix.T @ weight # Gets the projection of the image on the facespace\n",
    "\n",
    "    proj_error = np.linalg.norm(subtracted_matrix_rec - projection)*255 # Gets the projection error\n",
    "    \n",
    "\n",
    "    original_faces_weights = eigenfaces_matrix @ subtracted.T # Gets the eigenface weights of each original face\n",
    "\n",
    "\n",
    "    dist_in_space = []\n",
    "    # Checks the distance between the weights \n",
    "    # of the unknown face and every original face\n",
    "    for i in range(len(subtracted[:,0])):\n",
    "        dist = np.linalg.norm(original_faces_weights[:,i] - weight)\n",
    "        dist_in_space.append(dist)\n",
    "    \n",
    "    dist_in_space = np.array(dist_in_space)\n",
    "\n",
    "    face_error = dist_in_space.min() # Gets the lowest distance\n",
    "\n",
    "    guess_index = np.argmin(dist_in_space) # Gets the image tied to that lowest distance\n",
    "    \n",
    "    if proj_error > face_limit: # Checks if the error is higher than the set limit\n",
    "        guess = \"Not a face\"\n",
    "    elif face_error > person_limit:\n",
    "        guess = \"Unknown face\"\n",
    "    else:\n",
    "        celebrity_photos = os.listdir('data')\n",
    "        celebrity_names = [name[:name.find('0')-1].replace(\"_\", \" \") for name in celebrity_photos] # Gets the names of all images\n",
    "        guess = celebrity_names[guess_index] # Gets the predicted name\n",
    "\n",
    "    display_image(image_matrix[guess_index]) # Displays the closest image\n",
    "    return proj_error, face_error, guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'carol7'\n",
    "path_extra = os.path.join('extra_testing', name + '.jpg')\n",
    "display_image(read_image(path_extra))\n",
    "# plt.savefig(os.path.join('images', name + '.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recognize(path_extra, 106, 5000, 100))\n",
    "# plt.savefig(os.path.join('images', name + '_famoso.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(reconstruction_outsider(Vh, average_matrix, 150, 150, path_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images(path, eig_num, face_error, person_error):\n",
    "    success = 0\n",
    "    failure = 0\n",
    "    not_a_face = 0\n",
    "    unknown_face = 0\n",
    "    for file in os.listdir(path):\n",
    "        path_testing = os.path.join(path, file)\n",
    "        results = recognize(path_testing, eig_num, face_error, person_error)\n",
    "        if results[2] == \"Not a face\":\n",
    "            not_a_face += 1\n",
    "        elif results[2] == \"Unknown face\":\n",
    "            unknown_face += 1\n",
    "        elif results[2] == file[:file.find('0')-1].replace(\"_\", \" \"):\n",
    "            success += 1\n",
    "        else:\n",
    "            failure += 1\n",
    "\n",
    "    success = success*100/len(os.listdir(path))\n",
    "    failure = failure*100/len(os.listdir(path))\n",
    "    not_a_face = not_a_face*100/len(os.listdir(path))\n",
    "    unknown_face = unknown_face*100/len(os.listdir(path))\n",
    "    return success, failure, not_a_face, unknown_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate, failure_rate, not_face_rate, unknown_rate = test_images('data', 106, 3500, 22.2)\n",
    "success_rate, failure_rate, not_face_rate, unknown_rate"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
