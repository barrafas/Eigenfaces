{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    # Reads an image from the determined path\n",
    "    # The image has to have a bit-depth of 8 (each pixel's value is in the 0-255 range)\n",
    "    img_to_recognize = img.imread(path)\n",
    "    img_to_recognize = Image.fromarray(np.uint8(img_to_recognize))\n",
    "    img_to_recognize = img_to_recognize.resize((150, 150)) # Resizes the image to the appropriate size\n",
    "    img_to_recognize = img_to_recognize.convert('L') # Converts it to grayscale\n",
    "    img_to_recognize = np.array(img_to_recognize) # Converts it into an array\n",
    "    return img_to_recognize.flatten()/255 # Flattens and normalizes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_ind(matrix, index):\n",
    "    # Displays the image present in the row_{index} of the specified matrix\n",
    "    resized = np.resize(matrix[index], (150, 150))\n",
    "    fig = plt.imshow(resized, cmap=\"gray\")\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    fig\n",
    "\n",
    "\n",
    "def display_image(matrix):\n",
    "    # Displays the image present in the row_{index} of the specified matrix\n",
    "    resized = np.resize(matrix, (150, 150))\n",
    "    fig = plt.imshow(resized, cmap=\"gray\")\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    fig\n",
    "\n",
    "\n",
    "\n",
    "def plot_portraits(images, titles, h, w, n_row, n_col):\n",
    "    plt.figure(figsize=(2.2 * n_col, 2.2 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.20)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [] # List that will house all individual arrays of images, it will become a 2D array later\n",
    "\n",
    "for file in os.listdir('faces'):\n",
    "    images.append(read_image(os.path.join('faces', file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_photos=os.listdir('faces')\n",
    "celebrity_names=[name[:name.find('0')-1].replace(\"_\", \" \") for name in celebrity_photos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matrix = np.row_stack(tuple(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    # X is the data matrix, n_pc is the number of requested eigenvectors/components\n",
    "    mean = np.mean(X, axis=0)\n",
    "    centered_data = X-mean\n",
    "    U, S, Vh = np.linalg.svd(centered_data, full_matrices=False)\n",
    "    \n",
    "    return Vh, mean, centered_data, S**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh, average_matrix, subtracted, eigenvalues = pca(image_matrix)\n",
    "eigenfaces = Vh.reshape((434, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_eigenvalues = [eigenvalue/np.sum(eigenvalues) for eigenvalue in eigenvalues]\n",
    "count = 0\n",
    "total_var = 0\n",
    "\n",
    "for eigenvalue in percent_eigenvalues:\n",
    "    total_var += eigenvalue\n",
    "    count += 1\n",
    "    if total_var > 0.95:\n",
    "        break\n",
    "\n",
    "print(\"Count:\", count, \"\\nTotal Variance:\", total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(average_matrix)\n",
    "\n",
    "plt.savefig('average face.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenface_titles = [f\"eigenface {434-i}\" for i in range(eigenfaces.shape[0])]\n",
    "# plot_portraits(eigenfaces[::-1], eigenface_titles, 150, 150, 2, 5) \n",
    "# plt.savefig('lowest eigenfaces.png', bbox_inches='tight')\n",
    "\n",
    "eigenface_titles = [f\"eigenface {i+91}\" for i in range(eigenfaces.shape[0])]\n",
    "plot_portraits(eigenfaces[90:105,:], eigenface_titles, 150, 150, 2, 5) \n",
    "plt.savefig('medium eigenfaces.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_image_ind(image_matrix, 307)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_ind(image_matrix, 142)\n",
    "plt.savefig('original face.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(centered_data, eigenfaces, average, h, w, image_index):\n",
    "    weights = np.dot(centered_data, eigenfaces.T) # Gets the weight significance of each eigenface\n",
    "    weighted_vectors = np.dot(weights[image_index, :], eigenfaces) # Multiplies each eigenface by its weight\n",
    "    recovered_image = (average + weighted_vectors).reshape(h, w) # Adds each weighted eigenface to the average face\n",
    "    return recovered_image\n",
    "\n",
    "display_image(reconstruction(subtracted, Vh[:300,:], average_matrix, 150, 150, 142))\n",
    "plt.savefig('reconstructed full face.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_outsider(eigenfaces, average, h, w, path):\n",
    "    outsider = read_image(path) # Reads the image\n",
    "    outsider = outsider - average # Centralizes the data\n",
    "    weights = np.dot(outsider, eigenfaces.T) # Gets the weight significance of each eigenface\n",
    "    weighted_vectors = np.dot(weights, eigenfaces) # Multiplies each eigenface by its weight\n",
    "    recovered_image = (average + weighted_vectors).reshape(h, w) # Adds each weighted eigenface to the average face\n",
    "    return recovered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(path, eig_num, face_limit, person_limit):\n",
    "    # Path is the file path, eig_num is the amount of wanted eigenfaces on the facespace\n",
    "    img_to_recognize = read_image(path)\n",
    "    subtracted_matrix_rec = img_to_recognize - average_matrix # Centralizes the inputted image\n",
    "    subtracted_matrix_rec = subtracted_matrix_rec.flatten()\n",
    "\n",
    "    eigenfaces_matrix = Vh[:eig_num,:] # Gets the requested amount of eigenfaces\n",
    "\n",
    "    weight = subtracted_matrix_rec @ eigenfaces_matrix.T # Gets the eigenface weights\n",
    "\n",
    "    projection = eigenfaces_matrix.T @ weight # Gets the projection of the image on the facespace\n",
    "\n",
    "    proj_error = np.linalg.norm(subtracted_matrix_rec - projection) # Gets the projection error\n",
    "\n",
    "    if proj_error > face_limit: # Checks if the error is higher than the set limit\n",
    "        return \"Not a face!\"\n",
    "    \n",
    "\n",
    "    original_faces_weights = eigenfaces_matrix @ subtracted.T # Gets the eigenface weights of each original face\n",
    "\n",
    "\n",
    "    dist_in_space = []\n",
    "    # Checks the distance between the weights \n",
    "    # of the unknown face and every original face\n",
    "    for i in range(len(subtracted[:,0])):\n",
    "        dist = np.linalg.norm(original_faces_weights[:,i] - weight)\n",
    "        dist_in_space.append(dist)\n",
    "    \n",
    "    dist_in_space = np.array(dist_in_space)\n",
    "\n",
    "    face_error = dist_in_space.min() # Gets the lowest distance\n",
    "\n",
    "    # Trying to get the right face (range of valid error still to be determined)\n",
    "    guess_index = np.argmin(dist_in_space)\n",
    "    \n",
    "    celebrity_name = celebrity_names[guess_index]\n",
    "\n",
    "    display_image(image_matrix[guess_index])\n",
    "    return proj_error*255, face_error, celebrity_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_recon = os.path.join('objects', 'Keanu_Reeves_0008.pgm')\n",
    "display_image(read_image(path_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(reconstruction_outsider(Vh, average_matrix, 150, 150, path_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize(path_recon, 106, 3000, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# george = os.path.join('lfwcrop_grey', 'faces')\n",
    "\n",
    "# numbers = []\n",
    "# for number in range(9, 531):\n",
    "#     str_num = \"0\"*(4-len(str(number))) + str(number)\n",
    "#     numbers.append(str_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# george_list = []\n",
    "# for number in numbers:\n",
    "#     george_dict = {}\n",
    "#     george_dict[\"Projection Error\"], george_dict[\"Face Error\"], george_dict[\"Celebrity Name\"] = recognize2(george, 'George_W_Bush_', number, 100, '.pgm')\n",
    "#     george_list.append(george_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_names = []\n",
    "# for dic in george_list:\n",
    "#     pred_names.append(dic['Celebrity Name'])\n",
    "\n",
    "# pred_names = dict(collections.Counter(pred_names))\n",
    "\n",
    "# highest = 0 \n",
    "# for value in pred_names.values():\n",
    "#     if value > highest:\n",
    "#         highest = value\n",
    "\n",
    "# pred_names['George W Bush'], highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvalues)\n",
    "plt.xticks(range(0,200,20))\n",
    "plt.xlim(-1, 100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
